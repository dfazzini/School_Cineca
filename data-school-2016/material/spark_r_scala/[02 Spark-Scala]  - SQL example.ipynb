{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a SQL context on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Create a SQL context on the data\n",
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
    "\n",
    "// this is used to implicitly convert an RDD to a DataFrame.\n",
    "import sqlContext.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RDD, DataFrame and Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Create an RDD\n",
    "val people = sc.textFile(\"data/people.txt\")\n",
    "\n",
    "// The schema is encoded in a string\n",
    "val schemaString = \"name age\"\n",
    "\n",
    "// Import Row.\n",
    "import org.apache.spark.sql.Row;\n",
    "\n",
    "// Import Spark SQL data types\n",
    "import org.apache.spark.sql.types.{StructType,StructField,StringType};\n",
    "\n",
    "// Generate the schema based on the string of schema\n",
    "val schema =\n",
    "  StructType(\n",
    "    schemaString.split(\" \").map(fieldName => StructField(fieldName, StringType, true)))\n",
    "\n",
    "// Convert records of the RDD (people) to Rows.\n",
    "val rowRDD = people.map(_.split(\",\")).map(p => Row(p(0), p(1).trim))\n",
    "\n",
    "// Apply the schema to the RDD.\n",
    "val peopleDataFrame = sqlContext.createDataFrame(rowRDD, schema)\n",
    "\n",
    "// Register the DataFrames as a table.\n",
    "peopleDataFrame.registerTempTable(\"people\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SQL to query a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Michael\n",
      "Name: Andy\n",
      "Name: Justin\n",
      "Name: Michael\n",
      "[Michael,29]\n",
      "[Andy,30]\n",
      "[Justin,19]\n",
      "[Michael,29]\n"
     ]
    }
   ],
   "source": [
    "// SQL statements can be run by using the sql methods provided by sqlContext.\n",
    "val results = sqlContext.sql(\"SELECT name FROM people\")\n",
    "\n",
    "// The results of SQL queries are DataFrames and support all the normal RDD operations.\n",
    "// The columns of a row in the result can be accessed by field index or by field name.\n",
    "results.map(t => \"Name: \" + t(0)).collect().foreach(println)\n",
    "\n",
    "val results2 = sqlContext.sql(\"SELECT * FROM people\")\n",
    "results2.collect().foreach(println)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using  DataFrames commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      "\n",
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|Michael| 29|\n",
      "|   Andy| 30|\n",
      "| Justin| 19|\n",
      "|Michael| 29|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleDataFrame.printSchema()\n",
    "peopleDataFrame.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checked"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache_Toree",
   "language": "",
   "name": "apache_toree"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
